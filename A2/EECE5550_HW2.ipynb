{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkxjIur0iH-W"
      },
      "source": [
        "# HW2: Local Planning\n",
        "\n",
        "### EECE 5550: Mobile Robotics (Spring 2025)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gMxVX7yaLr"
      },
      "source": [
        "**Collaboration Statement:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXaBB3IJyxcb"
      },
      "outputs": [],
      "source": [
        "# Fill this in per the syllabus, or we will assign a zero to this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Q-SupywN0g"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaX3MKJZiWb3"
      },
      "source": [
        "This semester, we will use a custom simulator, called `gym-neu-racing`, to develop navigation algorithms. We implemented the basic structure of this simulator for you, and the HW assignments will ask you to implement important functions (e.g., kinematics, sensing, planning, mapping).\n",
        "\n",
        "To install the simulator, you can use this command (it will download the latest code from GitLab and automatically install it in the environment your Colab notebook runs in):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1a17fpJ9ONw"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://gitlab.com/neu-autonomy/gym-neu-racing.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U528T-DbjK3L"
      },
      "source": [
        "Now that the simulator and its dependencies have been installed, you can import the modules you'll need for this assignment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylskOzCW-VEt"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "import numpy as np\n",
        "import gym_neu_racing\n",
        "from gymnasium import spaces\n",
        "from gym_neu_racing.envs.wrappers import StateFeedbackWrapper\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Callable\n",
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as colors\n",
        "from gym_neu_racing import motion_models\n",
        "import cvxpy as cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKUvYLxpv2p4"
      },
      "source": [
        "# Problem 1: MPPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHr3pCDajeQr"
      },
      "source": [
        "## 1a) MPPI to move toward a goal coordinate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSN_vAxgrB7p"
      },
      "source": [
        "In this problem, you'll implement a basic version of MPPI and show that it outputs a good rollout to move a robot toward a given goal position. This part uses the Unicycle kinematic model that's built into the simulator. You should  make sure that your `get_action` method considers the control limits (otherwise it may command things that the robot can't execute), which may require passing those as arguments to the `__init__` method.\n",
        "\n",
        "You will probably need to experiment with different numbers of rollouts, cost functions, Î» values, numbers of iterations, etc. to get good performance.\n",
        "\n",
        "Keeping this code relatively organized and clean will help for later parts in the assignment, where you build on this implementation. For example, you are encouraged to define helper methods in your `MPPI` class to help keep your code organized (e.g., you may want a `score_rollouts` and/or `plot_rollouts` method that get called inside the `get_next_action` method).\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `MPPI` class, in particular the `get_next_action` method, so that the chosen rollout drives the robot toward the goal position.\n",
        "- Print the best control sequence your MPPI algorithm came up with (the first row/element of this sequence should be the action that your `get_action` returns)\n",
        "- Include a plot that shows the rollouts, start position, goal position, and highlights the best rollout in that iteration, for at least a few iterations. We expect that the later iterations will give much better rollouts than the first iteration. You should make your axes have the same scale (e.g., using `plt.axis('equal')`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLBNRUxk9biN"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the mobile robot simulator we'll use this semester\n",
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "# Tell the simulator to directly provide the current state vector (no sensors yet)\n",
        "env = StateFeedbackWrapper(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZJH3QRk3mRy"
      },
      "outputs": [],
      "source": [
        "class MPPI:\n",
        "    def __init__(\n",
        "        self,\n",
        "        motion_model=motion_models.Unicycle(),\n",
        "    ):\n",
        "        \"\"\" Your implementation here \"\"\"\n",
        "        self.motion_model = motion_model\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_action(self, initial_state: np.ndarray, goal_pos: np.ndarray):\n",
        "        \"\"\" Your implementation here \"\"\"\n",
        "        raise NotImplementedError\n",
        "        return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7KCd76vpd7O"
      },
      "source": [
        "You can use the following code to check whether your MPPI implementation is working. After tuning your algorithm, it should be able to come up with a rollout that ends close to the goal (within 0.1m in l2 distance is close enough):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MwJmizDsKT_"
      },
      "outputs": [],
      "source": [
        "# Initialize the environment (and set random seed so any randomness is repeatable)\n",
        "np.random.seed(0)\n",
        "obs, _ = env.reset()\n",
        "\n",
        "# Set the starting state (x, y, theta) and goal position (x, y).\n",
        "initial_state = np.array([0.0, 0.0, 0.0])\n",
        "goal_pos = np.array([0.5, 0.5])\n",
        "\n",
        "# Instantiate your contoller class\n",
        "controller = MPPI()\n",
        "\n",
        "# Run your control algorithm for 1 step. We'll worry about running your\n",
        "# algorithm in closed-loop in later parts of the assignment.\n",
        "action = controller.get_action(initial_state, goal_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbpVmsnFKLFE"
      },
      "source": [
        "## 1b) MPPI to drive around a racetrack\n",
        "\n",
        "Now you will extend your MPPI implementation so that your robot drives around a racetrack. There are a few interesting challenges you'll need to figure out that didn't appear in the earlier problem:\n",
        "\n",
        "*   How to score rollouts? Some possible ideas include placing waypoints around the track, designing a cost-to-go function, or encouraging the vehicle to maintain full speed, but this is completely up to you!\n",
        "*   How to ensure the robot doesn't collide with the walls? You can transform coordinates from the world frame to map cell indices using `self.static_map.world_coordinates_to_map_indices(states_in_world)` and `self.static_map.static_map[map_indices]` to check whether a cell of the map is occupied or free.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `MPPIRacetrack` class below to enable your robot to complete a full lap around the track\n",
        "- Generate a plot of the path taken with some indication of time (e.g., using a colorbar, timestamps every so often along the path, or another creative way you come up with)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHiwUnxOKOLa"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the mobile robot simulator we'll use this semester\n",
        "env = gymnasium.make(\"gym_neu_racing/NEURacing-v0\")\n",
        "\n",
        "# Tell the simulator to directly provide the current state vector (no sensors yet)\n",
        "env = StateFeedbackWrapper(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD7Tme-ON1bT"
      },
      "outputs": [],
      "source": [
        "class MPPIRacetrack:\n",
        "    def __init__(\n",
        "        self,\n",
        "        static_map,\n",
        "        motion_model=motion_models.Unicycle(),\n",
        "    ):\n",
        "        \"\"\" Your implementation here \"\"\"\n",
        "        self.motion_model = motion_model\n",
        "        self.static_map = static_map\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_action(self, initial_state: np.array) -> np.array:\n",
        "        \"\"\" Your implementation here \"\"\"\n",
        "        # raise NotImplementedError\n",
        "        # return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrYXKRJiOdTa"
      },
      "outputs": [],
      "source": [
        "def run_planner_on_racetrack(\n",
        "    env: gymnasium.Env,\n",
        "    planner_class=MPPIRacetrack,\n",
        "    seed: int = 0,\n",
        "    num_laps: int = 3,\n",
        ") -> int:\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    obs, _ = env.reset()\n",
        "    env.unwrapped.laps_left = num_laps\n",
        "\n",
        "    # Create an instance of your planner\n",
        "    planner = planner_class(static_map=env.unwrapped.map)\n",
        "\n",
        "    # Draw a map of the environment with the finish line + initial position\n",
        "    ax = env.unwrapped.map.draw_map(show=False)\n",
        "    ax.plot(\n",
        "        env.unwrapped.finish_line[:, 0],\n",
        "        env.unwrapped.finish_line[:, 1],\n",
        "        \"g\",\n",
        "        lw=3,\n",
        "    )\n",
        "    ax.plot(obs[0], obs[1], \"rx\")\n",
        "\n",
        "    # Run the environment for num_timesteps, unless the robot hits an obstacle\n",
        "    # or successfully completes the number of laps needed\n",
        "    num_timesteps = 500\n",
        "    success = False\n",
        "    for t in range(num_timesteps):\n",
        "        action = planner.get_action(obs)\n",
        "        obs, _, terminated, _, _ = env.step(action)\n",
        "\n",
        "        ax.plot(obs[0], obs[1], \"bx\")\n",
        "\n",
        "        if terminated:\n",
        "            success = True\n",
        "            break\n",
        "\n",
        "    num_timesteps_used = t\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    if success:\n",
        "        return num_timesteps_used\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "seed = 0\n",
        "num_laps = 3\n",
        "planner_class = MPPIRacetrack\n",
        "num_timesteps_used = run_planner_on_racetrack(\n",
        "    env, planner_class=planner_class, seed=seed, num_laps=num_laps\n",
        ")\n",
        "print(f\"num timesteps used: {num_timesteps_used}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0dX_C6SKOdz"
      },
      "source": [
        "## [Extra Credit] 1c) Compete for the fastest lap time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ4OYjItKayG"
      },
      "source": [
        "In this part, you can earn extra credit by achieving faster lap times (measured in average number of steps to complete the course, not computational runtime). You can get some extra credit by implementing a working version of something interesting here (e.g., another planning algorithm, a learning-based method, an extension beyond the basic MPPI we discussed in class). We will give additional extra credit to the student with the fastest lap time, which can be monitored on the Gradescope leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSk7vQxILMmh"
      },
      "outputs": [],
      "source": [
        "class BetterPlanner:\n",
        "    def __init__(self, static_map):\n",
        "        \"\"\"Store any hyperparameters here.\"\"\"\n",
        "        # raise NotImplementedError\n",
        "\n",
        "    def get_action(self, obs: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        \"\"\" Your implementation here \"\"\"\n",
        "        # raise NotImplementedError\n",
        "        # return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlewS2XauH8x"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "num_laps = 3\n",
        "planner_class = BetterPlanner\n",
        "run_planner_on_racetrack(\n",
        "    env, planner_class=planner_class, seed=seed, num_laps=num_laps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmxfA9IOr3oO"
      },
      "source": [
        "# Problem 2: Trajectory Optimization with `cvxpy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qyLx6u_sQoU"
      },
      "source": [
        "## 2a) Double Integrator: Initial & Terminal Conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwwMyELypADw"
      },
      "source": [
        "For this problem, you'll use the 2D discrete-time double integrator dynamics, where $$\\mathbf{x}[t] = \\begin{bmatrix}\n",
        "x[t]\\\\\n",
        "y[t]\\\\\n",
        "v_x[t]\\\\\n",
        "v_y[t]\\\\\n",
        "\\end{bmatrix}, \\quad \\mathbf{u}[t] = \\begin{bmatrix} a_x[t]\\\\ a_y[t]\\\\ \\end{bmatrix}, \\quad \\mathbf{x}[t+dt] = A \\mathbf{x}[t] +  B \\mathbf{u}[t], \\quad A = \\begin{bmatrix}\n",
        "1 & 0 & dt & 0 \\\\\n",
        "0 & 1 & 0 & dt \\\\\n",
        "0 & 0 & 1 & 0 \\\\\n",
        "0 & 0 & 0 & 1 \\\\\n",
        "\\end{bmatrix}, \\quad B = \\begin{bmatrix}\n",
        "\\frac{dt^2}{2} & 0 \\\\\n",
        "0 & \\frac{dt^2}{2} \\\\\n",
        "dt & 0 \\\\\n",
        "0 & dt \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "You should turn the following optimization problem into code:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\min_{x_{0:T}, u_{0:T}}\\quad & (x[T] - g_x)^2 + (y[T] - g_y)^2 \\\\\n",
        "\\text{s.t.}\\quad & \\mathbf{x}[t+1] = A \\mathbf{x}[t] + B \\mathbf{u}[t] \\quad \\forall t \\in \\{0, 1, \\ldots, T-1\\} \\\\\n",
        "& \\mathbf{u}[t] \\in U \\quad \\forall t \\in \\{0, 1, \\ldots, T-1\\} \\\\\n",
        "& \\mathbf{x}[0] = \\mathbf{x}_0 \\\\\n",
        "& v_x[T] = v_{x,T} \\\\\n",
        "& v_x[T] = v_{y,T} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "with $g_x = 3, g_y=5, v_{x,T}=0, v_{y,T}=0, \\mathbf{x}_0 = [1, 2, 0, 0], U = [-1, 1] \\times [-1, 1], T=10$.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement `optimize_trajectory`, which will take in initial and terminal conditions, control limits, dt, and return the optimal sequence of states (i.e., an array of shape (T+1, 4) -- T+1 timesteps (T timesteps + the initial state) and 4 states per timestep)\n",
        "- Generate a plot of your optimal trajectory. You are welcome to use the `plot_trajectory` function or write your own version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgHEnGozoeUD"
      },
      "outputs": [],
      "source": [
        "def optimize_trajectory(\n",
        "    initial_pos: np.ndarray,\n",
        "    initial_vel: np.ndarray,\n",
        "    goal_pos: np.ndarray,\n",
        "    goal_vel: np.ndarray,\n",
        "    u_limits: np.ndarray,\n",
        "    dt: float,\n",
        ") -> np.ndarray:\n",
        "    \"\"\" Your implementation here\"\"\"\n",
        "    raise NotImplementedError\n",
        "    return states\n",
        "\n",
        "\n",
        "def plot_trajectory(xt: np.ndarray) -> None:\n",
        "\n",
        "    # Feel free to add to this\n",
        "\n",
        "    plt.plot(xt[:, 0], xt[:, 1], \"-x\")\n",
        "    plt.axis(\"equal\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q1bRwpi2cWu"
      },
      "source": [
        "You can check whether your code works using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWoRpQs3t2iQ"
      },
      "outputs": [],
      "source": [
        "initial_pos = np.array([1.0, 2.0])\n",
        "initial_vel = np.array([0.0, 0.0])\n",
        "goal_pos = np.array([3.0, 5.0])\n",
        "goal_vel = np.array([0.0, 0.0])\n",
        "u_limits = 0.2 * np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
        "dt = 1.0\n",
        "\n",
        "optimal_xt = optimize_trajectory(\n",
        "    initial_pos,\n",
        "    initial_vel,\n",
        "    goal_pos,\n",
        "    goal_vel,\n",
        "    u_limits,\n",
        "    dt,\n",
        ")\n",
        "\n",
        "plot_trajectory(optimal_xt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGWONpFmHz6G"
      },
      "source": [
        "## [Extra Credit] 2b) Incorporate obstacle avoidance as a convex optimization problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV64hIZMIB_i"
      },
      "source": [
        "Now, you should extend your optimization code to handle a list of circular obstacles that the double integrator must avoid. We would like you to try to keep this as a convex optimization problem. If you just start adding constraints and costs, you will likely end up with a non-convex optimization problem, which are generally hard to solve.\n",
        "\n",
        "One possible way to keep the problem convex could be to break the free (i.e., non-obstacle) space into a set of convex regions, then split the trajectory into multiple segments (each one needing to stay within one convex region). But, there could be many other ways, and you are encouraged to try different strategies!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJybm9RcG2qL"
      },
      "outputs": [],
      "source": [
        "def optimize_trajectory_with_obstacles(\n",
        "    initial_pos: np.ndarray,\n",
        "    initial_vel: np.ndarray,\n",
        "    goal_pos: np.ndarray,\n",
        "    goal_vel: np.ndarray,\n",
        "    u_limits: np.ndarray,\n",
        "    dt: float,\n",
        "    obstacles: list,\n",
        ") -> np.ndarray:\n",
        "\n",
        "    \"\"\" Your implementation here\"\"\"\n",
        "    raise NotImplementedError\n",
        "    return states\n",
        "\n",
        "\n",
        "def plot_trajectory_with_obstacles(\n",
        "    xt: np.ndarray,\n",
        "    obstacles: list[np.ndarray],\n",
        ") -> None:\n",
        "\n",
        "    # Feel free to add to this\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(xt[:, 0], xt[:, 1], \"-x\")\n",
        "    for obstacle in obstacles:\n",
        "        ax.add_patch(plt.Circle(obstacle[0:2], obstacle[2], color=\"r\"))\n",
        "    plt.axis(\"equal\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-klRF2tt0quK"
      },
      "outputs": [],
      "source": [
        "initial_pos = np.array([1.0, 2.0])\n",
        "initial_vel = np.array([0.0, 0.0])\n",
        "goal_pos = np.array([3.0, 5.0])\n",
        "goal_vel = np.array([0.0, 0.0])\n",
        "u_limits = 0.2 * np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
        "dt = 1.0\n",
        "\n",
        "obstacles = [\n",
        "    (1.5, 2.5, 0.5),\n",
        "    (2.0, 3.5, 0.25),\n",
        "    (2.5, 4.0, 0.5),\n",
        "]\n",
        "\n",
        "optimal_xt = optimize_trajectory_with_obstacles(\n",
        "    initial_pos,\n",
        "    initial_vel,\n",
        "    goal_pos,\n",
        "    goal_vel,\n",
        "    u_limits,\n",
        "    dt,\n",
        "    obstacles,\n",
        ")\n",
        "\n",
        "plot_trajectory_with_obstacles(optimal_xt, obstacles)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l5Q-SupywN0g",
        "TKUvYLxpv2p4",
        "wmxfA9IOr3oO",
        "9qyLx6u_sQoU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}