{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l5Q-SupywN0g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW1: Mobile Robot Kinematics & Control\n",
        "\n",
        "### EECE 5550: Mobile Robotics (Spring 2025)\n"
      ],
      "metadata": {
        "id": "zkxjIur0iH-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration Statement:**"
      ],
      "metadata": {
        "id": "24gMxVX7yaLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill this in per the syllabus, or we will assign a zero to this assignment."
      ],
      "metadata": {
        "id": "QXaBB3IJyxcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "l5Q-SupywN0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This semester, we will use a custom simulator, called `gym-neu-racing`, to develop navigation algorithms. We implemented the basic structure of this simulator for you, and the HW assignments will ask you to implement important functions (e.g., kinematics, sensing, planning, mapping).\n",
        "\n",
        "To install the simulator, you can use this command (it will download the latest code from GitLab and automatically install it in the environment your Colab notebook runs in):"
      ],
      "metadata": {
        "id": "OaX3MKJZiWb3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1a17fpJ9ONw"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://gitlab.com/neu-autonomy/gym-neu-racing.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the simulator and its dependencies have been installed, you can import the modules you'll need for this assignment:"
      ],
      "metadata": {
        "id": "U528T-DbjK3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "import numpy as np\n",
        "import gym_neu_racing\n",
        "from gymnasium import spaces\n",
        "from gym_neu_racing.envs.wrappers import StateFeedbackWrapper\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Callable"
      ],
      "metadata": {
        "id": "ylskOzCW-VEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create an instance of the simulator that you'll build on throughout the assignment:"
      ],
      "metadata": {
        "id": "U_H4vC_UjVh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the mobile robot simulator we'll use this semester\n",
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "# Tell the simulator to directly provide the current state vector (no sensors yet)\n",
        "env = StateFeedbackWrapper(env)"
      ],
      "metadata": {
        "id": "KLBNRUxk9biN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1"
      ],
      "metadata": {
        "id": "TKUvYLxpv2p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1a) Run the baseline simulator & generate a plot"
      ],
      "metadata": {
        "id": "oHr3pCDajeQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of how to run the simulator for a few timesteps. In this assignment, we told the simulator to return the true state of the environment (in future assignments, we'll only give noisy sensor data).\n",
        "\n",
        "In this problem, you should make a plot of the system's state over time. This will be helpful as you debug future parts of the assignment. This part uses the Unicycle kinematic model that's built into the simulator.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `plot_path` method. At a minimum, you should plot the (x,y) position over time (the first 2 elements of the state vector). You are welcome to add other capabilities to your `plot_path` function as you go through the assignment (e.g., visualizing the heading angle and/or the goal coordinate), but this is not necessary for this part. You probably should make your axes have the same scale (e.g., using `plt.axis('equal')`)."
      ],
      "metadata": {
        "id": "rSN_vAxgrB7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_path(env: gymnasium.Env, observation_history: list[np.ndarray]) -> None:\n",
        "\n",
        "  ## Your Implementation Here ##\n",
        "  raise NotImplementedError"
      ],
      "metadata": {
        "id": "0MwJmizDsKT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_unicycle_controller(current_state: np.ndarray) -> np.ndarray:\n",
        "  return np.array([3., 0.2]) # [linear speed, angular speed]\n",
        "\n",
        "def simulate_n_steps(env: gymnasium.Env, num_steps: int, controller: Callable):\n",
        "\n",
        "  observation_history = []\n",
        "\n",
        "  obs, _ = env.reset()\n",
        "  observation_history.append(obs)\n",
        "  print(f\"initial state: {obs}\")\n",
        "\n",
        "  # run the simulator for a few steps and see how the state evolves\n",
        "  for _ in range(num_steps):\n",
        "    action = controller(obs)\n",
        "    obs, _, terminated, _, _ = env.step(action)\n",
        "    observation_history.append(obs)\n",
        "    print(f\"current state: {obs}\")\n",
        "    if terminated:\n",
        "      break\n",
        "\n",
        "  return observation_history"
      ],
      "metadata": {
        "id": "JkI_qKAOudzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell the simulator to its built-in kinematic model\n",
        "env.unwrapped.motion_model = gym_neu_racing.motion_models.Unicycle()\n",
        "\n",
        "# Run the simulation and plot the path taken\n",
        "num_steps = 10\n",
        "observation_history = simulate_n_steps(env, num_steps, dummy_unicycle_controller)\n",
        "plot_path(env, observation_history)"
      ],
      "metadata": {
        "id": "sMt4OSl2jnIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) Implement a discrete-time unicycle kinematic model\n",
        "\n",
        "In lecture, we gave the continuous time kinematic model for a unicycle in the form of an ODE (i.e., $\\dot{x} = f(x, u)$). In this problem, you should use a simple first-order method (the Euler method) to solve this ODE at discrete timesteps from an initial state, $x[t+dt] = g(x[t], u[t], dt)$.\n",
        "\n",
        "You should also make sure that your `step` function clips the action so as to respect the control limits. As a hint, you can use `np.clip` and access the control limits with `self.action_space.low` and `self.action_space.high`.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `step` method of the `Unicycle` class below\n",
        "- Generate a plot of the path using your `plot_path` function from above"
      ],
      "metadata": {
        "id": "Yt1NCBYJ-0Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym_neu_racing.motion_models.motion_model import MotionModel\n",
        "\n",
        "\n",
        "class Unicycle(MotionModel):\n",
        "    def __init__(self, v_min=0, v_max=1, w_min=-2*np.pi, w_max=2*np.pi):\n",
        "        self.action_space = spaces.Box(np.array([v_min, w_min]),\n",
        "                                       np.array([v_max, w_max]),\n",
        "                                       shape=(2,),\n",
        "                                       dtype=float)\n",
        "        super().__init__()\n",
        "\n",
        "    def step(self, current_state: np.ndarray, action: np.ndarray, dt: float = 0.1) -> np.ndarray:\n",
        "        # current_state = np.array([x, y, theta])\n",
        "        # action = np.array([vx, vw])\n",
        "\n",
        "        ## Your Implementation Here ##\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return next_state\n"
      ],
      "metadata": {
        "id": "DjhEslk3997l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tell the simulator (`env`) to use your kinematic model by setting `env.motion_model = YourMotionModel()` (a small caveat is that we have some [wrappers](https://gymnasium.farama.org/api/wrappers/) around the simulator, so you should use the `unwrapped` attribute to directly modify attributes of the base simulator). The simulator will call your motion model's `step` method each timestep (i.e., `self.motion_model.step(self.state.copy(), action)`). To test your kinematic model, you can use the same general idea as before:"
      ],
      "metadata": {
        "id": "5xa45XIN_FUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell the simulator to use your kinematic model from above\n",
        "env.unwrapped.motion_model = Unicycle()\n",
        "\n",
        "# Run the simulation (using the dummy_unicycle controller) and plot the path taken\n",
        "num_steps = 10\n",
        "observation_history = simulate_n_steps(env, num_steps, dummy_unicycle_controller)\n",
        "plot_path(env, observation_history)"
      ],
      "metadata": {
        "id": "CP09ZeZ--wyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) Implement a discrete-time Simple Car kinematic model\n",
        "\n",
        "[Section 13.1.2 of Lavelle's book](https://lavalle.pl/planning/ch13.pdf) provides a good explanation of the Simple Car kinematics. In this part, you should implement a first-order discrete time approximation of this model.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `SimpleCar` class below"
      ],
      "metadata": {
        "id": "BNTz9Vafh1sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCar(MotionModel):\n",
        "    def __init__(self, L=1., v_min=-1, v_max=1, phi_min=-np.pi/4, phi_max=np.pi/4):\n",
        "        self.action_space = spaces.Box(-1, 1, shape=(2,), dtype=float)\n",
        "        self.L = L\n",
        "        super().__init__()\n",
        "\n",
        "    def step(self, current_state: np.ndarray, action: np.ndarray, dt: float = 0.1) -> np.ndarray:\n",
        "        # current_state = np.array([x, y, theta])\n",
        "        # action = np.array([u_s, u_phi])\n",
        "\n",
        "        ## Your Implementation Here ##\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return next_state"
      ],
      "metadata": {
        "id": "7m459AjAOfmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_car_controller(current_state: np.ndarray) -> np.ndarray:\n",
        "  return np.array([0.5, -0.1]) # [linear speed, steering angle]"
      ],
      "metadata": {
        "id": "o-r91GOBxNbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell the simulator to use your kinematic model from above\n",
        "env.unwrapped.motion_model = SimpleCar(L=0.5)\n",
        "\n",
        "# Run the simulation (using the dummy car controller) and plot the path taken\n",
        "num_steps = 10\n",
        "observation_history = simulate_n_steps(env, num_steps, dummy_car_controller)\n",
        "plot_path(env, observation_history)"
      ],
      "metadata": {
        "id": "Q6KjLQJ2PnIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: Controlling the Robot to Reach a Goal Coordinate"
      ],
      "metadata": {
        "id": "HtK4LxIniB-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2a) Open-Loop Control"
      ],
      "metadata": {
        "id": "5DOe2C7JhJcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `Unicycle` model you implemented above, you will now command the system to reach a goal position. Start with open-loop control, i.e., measure the intial state (returned by `env.reset`) and then calculate a sequence of actions to apply.\n",
        "\n",
        "After that sequence is computed, run the simulator forward for several steps, and at each step, simply grab the corresponding control value from that pre-computed sequence. You can use this example `open_loop_control_policy` implementation as a first try.\n",
        "\n",
        "Your job is to implement a smarter `open_loop_control_policy` that gets the system to reach (close) to the goal.\n",
        "\n",
        "Remember: you are only provided with the initial state, goal position, and the maximum number of steps allowed -- you can't access the system's state once it has started moving! That would be closed-loop control, which we'll implement next :)\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `open_loop_control_policy`, which should produce a sequence of control commands that will lead to the goal. This can be a very simple hard-coded policy (e.g., always send the same v, w)\n",
        "- Generate 1 plot that shows your open-loop controller drives the noise-free system to the goal (it only has to work for 1 test case). Include the path taken and the start/goal coordinates in your plot.\n",
        "- Generate 1 plot that shows your open-loop controller running on the noisy system (it's ok if it doesn't work on this system). Include the path taken and the start/goal coordinates in your plot."
      ],
      "metadata": {
        "id": "pLlKpzZKzG37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_loop_control_policy(init_state: np.ndarray, goal: np.ndarray, num_steps: int = 10) -> list[np.ndarray]:\n",
        "\n",
        "  ## Your Implementation Here ##\n",
        "  raise NotImplementedError\n",
        "\n",
        "  return control_sequence"
      ],
      "metadata": {
        "id": "aOWwHTVJaJ88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "max_num_steps = 200\n",
        "\n",
        "env.unwrapped.motion_model = Unicycle()\n",
        "obs, _ = env.reset() # initial observation of the system's state vector\n",
        "observation_history = [obs]\n",
        "\n",
        "# query your open loop controller based on the initial state of the system\n",
        "control_sequence = open_loop_control_policy(obs, env.goal, num_steps=max_num_steps)\n",
        "\n",
        "# Now that we've computed the control sequence, run the system forward until\n",
        "# we reach max_num_steps or the system's state is close to the goal\n",
        "for step in range(max_num_steps):\n",
        "  action = control_sequence[step]\n",
        "  obs, _, terminated, _, _ = env.step(action)\n",
        "  observation_history.append(obs)\n",
        "  if terminated:\n",
        "    break\n",
        "\n",
        "# Generate a simple plot of the path taken\n",
        "plot_path(env, observation_history)\n",
        "\n",
        "if terminated:\n",
        "  print('Success! Your open-loop controller drove the system to the goal.')\n",
        "else:\n",
        "  print('Your open-loop controller did not successfully drive the system to the goal.')"
      ],
      "metadata": {
        "id": "GtxCyNUiZtaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see what happens if we try that same `control_sequence` on a version of the environment where the wheels are a little bit slippery, so our simple unicycle model does not describe the true system perfectly.\n",
        "\n"
      ],
      "metadata": {
        "id": "ABmKxZnoZuFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NoisyUnicycle(Unicycle):\n",
        "  \"\"\"Same as Unicycle but add process noise at each step.\"\"\"\n",
        "  def __init__(self,\n",
        "               process_noise_limits=np.array([0.1, 0.1, 0.5]),\n",
        "               v_min=0, v_max=1, w_min=-2*np.pi, w_max=2*np.pi):\n",
        "    self.process_noise_limits = process_noise_limits\n",
        "    super().__init__(v_min=v_min, v_max=v_max, w_min=w_min, w_max=w_max)\n",
        "\n",
        "  def step(self, current_state, action, dt=0.1) -> np.ndarray:\n",
        "\n",
        "    \"\"\"Add process noise to the parent kinematics model.\"\"\"\n",
        "    next_state = super().step(current_state, action, dt=dt)\n",
        "    perturbed_next_state = next_state + np.random.uniform(low=-self.process_noise_limits, high=self.process_noise_limits)\n",
        "\n",
        "    return perturbed_next_state"
      ],
      "metadata": {
        "id": "v6RqTRHb9Aq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class we wrote for you will make it so you can't perfectly measure the system's state. It adds random noise to the `obs` that the `env` returns at each step:"
      ],
      "metadata": {
        "id": "CfshG9oH3X9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium import ObservationWrapper\n",
        "\n",
        "class NoisyStateFeedbackWrapper(ObservationWrapper):\n",
        "  def __init__(self, env, sensor_noise_limits=np.array([0.05, 0.05, 0.2])):\n",
        "    self.sensor_noise_limits = sensor_noise_limits\n",
        "    super().__init__(env)\n",
        "\n",
        "  def observation(self, observation: dict) -> np.ndarray:\n",
        "    obs = observation[\"state\"] + np.random.uniform(low=-self.sensor_noise_limits, high=self.sensor_noise_limits)\n",
        "    return obs"
      ],
      "metadata": {
        "id": "JAkFDyhA2fkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, run your open loop controller on a Unicycle with both process & sensor noise. Your open-loop control sequence probably does not drive the system to the goal anymore. This is to be expected! It's like trying to park a car in a parking spot with your eyes closed. We will implement a much smarter strategy next."
      ],
      "metadata": {
        "id": "87P0OMUo5I6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "max_num_steps = 200\n",
        "\n",
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "# Add both sensor noise & process noise to make the problem more challenging\n",
        "env = NoisyStateFeedbackWrapper(env)\n",
        "env.unwrapped.motion_model = NoisyUnicycle()\n",
        "\n",
        "obs, _ = env.reset() # initial observation of the system's state vector\n",
        "observation_history = [obs]\n",
        "\n",
        "# query your open loop controller based on the initial state of the system\n",
        "control_sequence = open_loop_control_policy(obs, env.goal, num_steps=max_num_steps)\n",
        "\n",
        "# Now that we've computed the control sequence, run the system forward until\n",
        "# we reach max_num_steps or the system's state is close to the goal\n",
        "for step in range(max_num_steps):\n",
        "  action = control_sequence[step]\n",
        "  obs, _, terminated, _, _ = env.step(action)\n",
        "  observation_history.append(obs)\n",
        "  if terminated:\n",
        "    break\n",
        "\n",
        "# Generate a simple plot of the path taken\n",
        "plot_path(env, observation_history)\n",
        "\n",
        "if terminated:\n",
        "  print('Success! Your open-loop controller drove the system to the goal.')\n",
        "else:\n",
        "  print('Your open-loop controller did not successfully drive the system to the goal.')"
      ],
      "metadata": {
        "id": "MNc1Qpr3acFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2b) Closed-Loop Control: Pure Pursuit Algorithm"
      ],
      "metadata": {
        "id": "vd22chkdhTSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most powerful ideas in robotic control is *feedback*. In this next part, we will implement a controller that measures the system's state at each step and uses that measurement to compute an action. This way, if the system ended up in a slightly different state than was expected from the simple model, the measurement will contain information about this discrepancy. Feedback control is often a great way to compensate for imperfect knowledge of the system you are working with.\n",
        "\n",
        "Your job is to implement the `PurePursuitController` class with a `get_action` method that takes in the current `obs` and the `env.goal` coordinate (expressed in the global frame), and outputs one `action` = $[v, \\omega]$. This `get_action` method will be called at each step, so there is no need to calculate a whole sequence of actions. The controller that you implement should be capable of driving the system to the goal."
      ],
      "metadata": {
        "id": "Fw8uqB1YzJwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PurePursuitController:\n",
        "  def __init__(self, L=3.):\n",
        "    \"\"\"Store any hyperparameters here.\"\"\"\n",
        "    self.L = L\n",
        "\n",
        "  def get_action(self, obs: np.ndarray, goal: np.ndarray) -> np.ndarray:\n",
        "\n",
        "    \"\"\"Your implementation goes here\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return np.array([linear_speed, angular_speed])"
      ],
      "metadata": {
        "id": "IvqtrX06bnfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `validation` function may come in handy for debugging/testing your controller in some random scenarios"
      ],
      "metadata": {
        "id": "U5zSc7FnpifI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(controller, motion_model=Unicycle, sensor_model=StateFeedbackWrapper, plot=False, num_runs=100, max_num_steps_per_run=200):\n",
        "  success_per_run = np.empty((num_runs,), dtype=bool)\n",
        "  num_steps_per_run = np.empty((num_runs,))\n",
        "  for i in range(num_runs):\n",
        "    np.random.seed(i)\n",
        "    env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "    env = sensor_model(env)\n",
        "    env.unwrapped.motion_model = motion_model()\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    observation_history = [obs]\n",
        "    for step in range(max_num_steps_per_run):\n",
        "      action = controller.get_action(obs, env.goal)\n",
        "      obs, _, terminated, _, _ = env.step(action)\n",
        "      observation_history.append(obs)\n",
        "      if terminated:\n",
        "        break\n",
        "\n",
        "    success_per_run[i] = terminated\n",
        "    num_steps_per_run[i] = step\n",
        "    if plot: plot_path(env, observation_history)\n",
        "\n",
        "  avg_success = np.mean(success_per_run)\n",
        "  avg_steps = np.mean(num_steps_per_run)\n",
        "  return avg_success, avg_steps"
      ],
      "metadata": {
        "id": "xrzoKrQtawn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, you can run your controller on 3 random cases and plot the resulting paths:"
      ],
      "metadata": {
        "id": "l1pWen-Rprg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pure_pursuit_controller = PurePursuitController(L=3.)\n",
        "validation(controller=pure_pursuit_controller, num_runs=3, plot=True)"
      ],
      "metadata": {
        "id": "tBrAz03NgMS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you're happy with your controller, you can run it against a larger validation test suite. This function will return the success rate (between 0 and 1) and average number of steps it takes your system to reach the goal."
      ],
      "metadata": {
        "id": "jinhElEOpKKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pure_pursuit_controller = PurePursuitController()\n",
        "avg_success, avg_steps = validation(controller=pure_pursuit_controller)\n",
        "print(\"Success rate:\", avg_success)\n",
        "print(\"Avg. Number of Steps:\", avg_steps)"
      ],
      "metadata": {
        "id": "Fec5qApopJHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a closed-loop controller that will drive the system to the goal.\n",
        "\n",
        "Let's see if that controller can handle the noisy version of the Unicycle model:"
      ],
      "metadata": {
        "id": "9pRJmv1bp94l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pure_pursuit_controller = PurePursuitController()\n",
        "avg_success, avg_steps = validation(controller=pure_pursuit_controller, motion_model=NoisyUnicycle, sensor_model=NoisyStateFeedbackWrapper, num_runs=5, plot=True)\n",
        "print(\"Success rate:\", avg_success)\n",
        "print(\"Avg. Number of Steps:\", avg_steps)"
      ],
      "metadata": {
        "id": "P09gn_6SyYWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully the answer is yes! Even though the vehicle doesn't perfectly follow the curve that the pure pursuit algorithm had in mind, the feedback control strategy compensates for the imperfect knowledge of the dynamics and drives the system to the goal."
      ],
      "metadata": {
        "id": "soqydewhqbpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables**:\n",
        "- Implement the `PurePursuitController` class using the ideas presented in Lecture 2. For partial credit, get a success rate of 100%. For full credit, get a success rate of 100% with an average number of steps below 82\n",
        "- Include plots and text (one paragraph maximum) below describing your observations about the impact of hyperparameters on your algorithm.\n",
        "\n",
        "Note: The autograder will simply instantiate your controller by running `PurePursuitController()`, so make sure that any hyperparameters default to the values you would like (e.g., use keyword arguments with default values for your lookahead distance)."
      ],
      "metadata": {
        "id": "mgTNyWkcsToC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2c) Extra Credit: Make your algorithm even better"
      ],
      "metadata": {
        "id": "Z0_CJ8k7q0LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prof. Everett's simple pure pursuit implementation used an average number of steps of 79.44 on the validation set. You can earn 1 extra credit point if you upload a second implementation to Gradescope achieves below 80 steps on average (while also achieving 100% success). You can earn additional extra credit for having the best implementation in the class according to the Gradescope leaderboard.\n",
        "\n",
        "You can try different strategies than just pure pursuit. Whichever control strategy you end up using, please use the `BetterController` class below for this part, which has the same class/function signatures as before.\n",
        "\n",
        "Note: there will be a test suite that is similar but not identical to the validation method above to ensure your algorithm doesn't overfit to specific cases."
      ],
      "metadata": {
        "id": "u6fRRQLi0JVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BetterController:\n",
        "  def __init__(self, L=3.):\n",
        "    \"\"\"Store any hyperparameters here.\"\"\"\n",
        "    self.L = L\n",
        "\n",
        "  def get_action(self, obs: np.ndarray, goal: np.ndarray) -> np.ndarray:\n",
        "\n",
        "    \"\"\"Your implementation goes here\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return np.array([linear_speed, angular_speed])"
      ],
      "metadata": {
        "id": "adMms5zftvxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}